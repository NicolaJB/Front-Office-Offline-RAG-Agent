# Answer using provided context only; cite chunks like [doc@start:end].

with open("prompts/answer_system.txt") as f:
    system_prompt = f.read()

prompt = f"{system_prompt}\n\nContext:\n{retrieved_context}\n\nQuestion: {query}"
answer = llm.generate(prompt)

